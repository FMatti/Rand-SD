\chapter{Numerical experiments}
\label{chp:5-experiments}

In the previous chapters we have introduced multiple methods for approximating the
spectral density of a symmetric matrix $\mtx{A} \in \mathbb{R}^{n \times n}$. Now,
our goal is to compare these methods with each other and with other related methods
in terms of their accuracy and speed. In order to do so, we apply these algorithms
in multiple scenarios. We consider a specific example from density functional theory
\cite{lin2017randomized} for two different \gls{smoothing-kernel}, and
subsequently test the methods on various other matrices.\\

The accuracy is measured in terms of the discrete relative $L^1$ error of the approximated
spectral density $\tilde{\phi}_{\sigma}^m$ from the spectral density $\phi_{\sigma}$
which we obtain using standard eigenvalue solvers\footnote{\url{https://numpy.org/doc/stable/reference/generated/numpy.linalg.eigvalsh.html}}.
\begin{equation}
    \frac{\sum_{i=1}^{n_t} |\widetilde{\phi}_{\sigma}^m(t_i) - \phi_{\sigma}(t_i)|}{\sum_{i=1}^{n_t} |\phi_{\sigma}(t_i)|}.
    \label{equ:5-experiments-L1-error}
\end{equation}
We use $n_t=100$ evenly spaced evaluation points covering the whole spectrum of
$\mtx{A}$. The choice of this metric can be justified by the fact that this
error is the midpoint quadrature rule applied to \todo{refer to choice of metric} \cite[chapter~9.2.1]{quarteroni2007numerical}. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Model problem from density functional theory}
\label{sec:5-experiments-density-function}

For our first example, we assemble the matrix which arises from the second order
finite difference discretization of the differential operator
\begin{equation}
    \mathcal{A} u(\vct{x}) = - \Delta u(\vct{x}) + V(\vct{x}) u(\vct{x})
    \label{equ:5-experiments-electronic-hamiltonian}
\end{equation}
for a uniform mesh of size $h=0.6$. The potential $V$ results from a
lattice whose primitive cell is of side-length $L=6$ and in whose center the
charge
\begin{equation}
    \alpha \exp(-\frac{\lVert \vct{x} \rVert _2^2}{ 2 \beta^2 })
    \label{equ:5-experiments-gaussian-cell}
\end{equation}
with $\alpha = 4$, $\beta = 2$ is located. The computational domain is chosen
to span $c$ primitive cells in every spatial dimension, hence, yielding
discretization matrices which are growing in size with $c$. In our experiments
we consider the three-dimensional case, but for visualization purposes, we
illustrate the potential in \reffig{fig:5-experiments-periodic-gaussian-well}
in two dimensions.\\
\begin{figure}[ht]
    \begin{subfigure}[b]{0.32\columnwidth}
        \input{plots/periodic_gaussian_well_1.pgf}
        \caption{$c=1$}
        \label{fig:5-experiments-periodic-gaussian-well-1}
    \end{subfigure}
    \begin{subfigure}[b]{0.32\columnwidth}
        \input{plots/periodic_gaussian_well_2.pgf}
        \caption{$c=2$}
        \label{fig:5-experiments-periodic-gaussian-well-2}
    \end{subfigure}
    \begin{subfigure}[b]{0.32\columnwidth}
        \input{plots/periodic_gaussian_well_5.pgf}
        \caption{$c=5$}
        \label{fig:5-experiments-periodic-gaussian-well-5}
    \end{subfigure}
    \caption{Two dimensional periodic potential $V$ for different sizes $c$ of the computational domain.}
    \label{fig:5-experiments-periodic-gaussian-well}
\end{figure}

For Gaussian \gls{smoothing-kernel} \refequ{equ:1-introduction-def-gaussian-kernel}
with \gls{smoothing-parameter} $=0.05$ we plot for two choices of \gls{chebyshev-degree}
the convergence of the error with \gls{sketch-size} in \reffig{fig:5-experiments-electronic-structure-convergence-nv}
and equally for two choices of \gls{sketch-size} the convergence of the
error with \gls{chebyshev-degree} in \reffig{fig:5-experiments-electronic-structure-convergence-nv}.

\begin{figure}[ht]
    \begin{subfigure}[b]{0.45\columnwidth}
        \input{plots/electronic_structure_convergence_nv_m800.pgf}
        \caption{$m=800$}
        \label{fig:5-experiments-electronic-structure-convergence-nv-m800}
    \end{subfigure}
    \begin{subfigure}[b]{0.5\columnwidth}
        \input{plots/electronic_structure_convergence_nv_m2400.pgf}
        \caption{$m=2400$}
        \label{fig:5-experiments-electronic-structure-convergence-nv-m2400}
    \end{subfigure}
    \caption{Behavior with $n_{\mtx{\Omega}}$ for $\sigma=0.05$}
    \label{fig:5-experiments-electronic-structure-convergence-nv}
\end{figure}

\begin{figure}[ht]
    \centering
    \begin{subfigure}[b]{0.45\columnwidth}
        \input{plots/electronic_structure_convergence_m_nv40.pgf}
        \caption{$n_{\mtx{\Omega}}=40$}
        \label{fig:5-experiments-electronic-structure-convergence-m-nv40}
    \end{subfigure}
    \begin{subfigure}[b]{0.5\columnwidth}
        \input{plots/electronic_structure_convergence_m_nv160.pgf}
        \caption{$n_{\mtx{\Omega}}=160$}
        \label{fig:5-experiments-electronic-structure-convergence-m-nv160}
    \end{subfigure}
    \caption{Behavior with $m$ for $\sigma=0.05$}
    \label{fig:5-experiments-electronic-structure-convergence-m}
\end{figure}

In \reftab{tab:5-experiments-timing-DGC} we list the wall time each method
takes to compute an approximate \gls{spectral-density} at $n_t=100$ points
for different values of \gls{sketch-size} and \gls{chebyshev-degree}.

\begin{table}[ht]
    \caption{Runtime comparison}
    \label{tab:5-experiments-timing-DGC}
    \input{tables/timing_DGC.tex}
\end{table}

Back in \refchp{chp:3-nystrom} we already saw that for small values of \gls{smoothing-parameter}
the Nystr\"om approximation will only need a small \gls{sketching-matrix} in order
to achieve an accurate approximation. On the other hand, for large choices of
\gls{smoothing-parameter} the low-rank approximation will by itself not suffice.
The interplay between the two parts which make up the \gls{NCPP},
on one hand the low-rank approximation and on the other hand the
trace estimation on the residual, is illustrated well in
\reffig{fig:5-experiments-electronic-structure-matvec-mixture}.
For various values of \gls{smoothing-parameter} and a simultaneously changing
\gls{chebyshev-degree} $=120 / \sigma$ to keep an approximately equal interpolation
accuracy, the behavior of the error for fixed $n_{\mtx{\Omega}} + \widetilde{n}_v = 80$ is plotted.

\begin{figure}[ht]
    \centering
    \input{plots/electronic_structure_matvec_mixture.pgf}
    \caption{Allocation of mat-vecs to low-rank and trace approximation.}
    \label{fig:5-experiments-electronic-structure-matvec-mixture}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Benchmark against Haydock's method}
\label{sec:5-experiments-haydock-method}

Haydock's method \cite{haydock1972electronic,lin2016review} is a specialized technique for approximating \gls{smooth-spectral-density}
in the case where a Lorentzian smoothing kernel
\begin{equation}
    g_{\sigma}(t) = \frac{1}{\pi} \frac{\sigma}{t^2 + \sigma^2} = -\frac{1}{\pi} \Imag\left\{ \frac{1}{t + i\sigma} \right\}
    \label{equ:5-experiments-cauchy-kernel}
\end{equation}
is used.
%Estimating \gls{smooth-spectral-density} then becomes the
%trace estimation problem
%\begin{equation}
%    \phi_{\sigma}(t) = \Tr(g_{\sigma}(t\mtx{I} - \mtx{A})) = - \frac{1}{n \pi} \Imag \left\{ \Tr\left[((t + i\sigma)I - A)^{-1}\right]  \right\}.
%    \label{equ:5-experiments-haydock-trace}
%\end{equation}
%Similarly to the \gls{DGC} method (see \refsec{sec:2-chebyshev-delta-gauss-chebyshev}),
%the Hutchinson's trace estimator with standard Gaussian random vectors
%$\vct{\psi} \in \mathbb{R}^n$ is used to
%approximate the trace
%\begin{equation}
%    \Tr\left[((t + i\sigma)I - A)^{-1}\right] \approx \frac{1}{n_{\mtx{\Omega}}} \sum_{j=1}^{n_{\mtx{\Omega}}} \left( \vct{\psi}_j \right)^{\top} ((t - i\sigma)\mtx{I} - \mtx{A})^{-1} \vct{\psi}_j.
%    \label{equ:5-experiments-haydock-hutchinson}
%\end{equation}
%It turns out that each summand in \refequ{5-experiments-haydock-hutchinson} can
%be efficiently evaluated for multiple $t$ by running Lanczos
%on $\mtx{A}$ with starting vector $\vct{\psi}_j$
%\begin{equation}
%    \vct{\psi}_j^{\top} ((t - i\sigma)\mtx{I} - \mtx{A})^{-1} \vct{\psi}_j% &\approx \vct{e}_1^{\top} ((t - i\sigma)\mtx{I} - \mtx{H}_k)^{-1} \vct{e}_1 \notag \\
%    \approx \cfrac{1}{(t - i\sigma) - \alpha_1 - \cfrac{\beta_2^2}{(t - i\sigma) - \alpha_2 - \dots}}
%    \label{equ:5-experiments-haydock-recursion}
%\end{equation}

We repeat the exact same experiments from \refsec{sec:5-experiments-density-function},
plot the results in \reffig{fig:5-experiments-haydock-convergence-nv} and
\reffig{fig:5-experiments-haydock-convergence-m}, and compare the wall time
between the methods in \reftab{tab:5-experiments-timing-haydock}.

\begin{figure}[ht]
    \begin{subfigure}[b]{0.45\columnwidth}
        \input{plots/haydock_convergence_nv_m800.pgf}
        \caption{$m=800$}
        \label{fig:5-experiments-haydock-convergence-nv-m800}
    \end{subfigure}
    \begin{subfigure}[b]{0.5\columnwidth}
        \input{plots/haydock_convergence_nv_m2400.pgf}
        \caption{$m=2400$}
        \label{fig:5-experiments-haydock-convergence-nv-m2400}
    \end{subfigure}
    \caption{Behavior with $n_{\mtx{\Omega}}$ for $\sigma=0.05$}
    \label{fig:5-experiments-haydock-convergence-nv}
\end{figure}

\begin{figure}[ht]
    \centering
    \begin{subfigure}[b]{0.45\columnwidth}
        \input{plots/haydock_convergence_m_nv40.pgf}
        \caption{$n_{\mtx{\Omega}}=40$}
        \label{fig:5-experiments-haydock-convergence-m-nv40}
    \end{subfigure}
    \begin{subfigure}[b]{0.5\columnwidth}
        \input{plots/haydock_convergence_m_nv160.pgf}
        \caption{$n_{\mtx{\Omega}}=160$}
        \label{fig:5-experiments-haydock-convergence-m-nv160}
    \end{subfigure}
    \caption{Behavior with $m$ for $\sigma=0.05$}
    \label{fig:5-experiments-haydock-convergence-m}
\end{figure}

\begin{table}[ht]
    \caption{Runtime comparison}
    \label{tab:5-experiments-timing-haydock}
   \input{tables/timing_haydock.tex}
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Application to various matrices}
\label{sec:5-experiments-various-matrices}

\todo{[Same plots for multiple matrices]}

\todo{Maybe comparison with SLQ, KPM, ...}

%\begin{figure}[ht]
%    \centering
%    \input{plots/multi_matrix_convergence_ModES3D_8.pgf}
%    \caption{$n_{\mtx{\Omega}}=160$}
%    \label{fig:5-experiments-multi-matrix-convergence}
%\end{figure}
