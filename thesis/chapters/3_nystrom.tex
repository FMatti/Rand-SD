\chapter{Randomized low-rank approximation}
\label{chp:3-nystrom}

Motivate low-rank approximation.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{The numerical rank of a matrix}
\label{sec:3-nystrom-numerical-rank}

Low-rank structure of matrix.
Formula for $\varepsilon$-numerical rank \cite[Definition~1.1]{noga2013rank} of a matrix $\mtx{B} \in \mathbb{R}^{n \times n}$
\begin{equation}
    r_{\varepsilon, \cdot}(\mtx{B}) = \min \{\rank(\mtx{C}): \mtx{C} \in \mathbb{R}^{n \times n}: \lVert \mtx{B} - \mtx{C} \rVert _{\cdot} \leq \varepsilon \}
    \label{equ:3-nystrom-SS-def-numerical-low-rank}
\end{equation}

For unitarily invariant norms \cite[Theorem~5]{mirsky1960truncation},
Eigenvalues $\mu_1, \dots, \mu_n$ of symmetric matrix $\mtx{B}$
For spectral norm,
\begin{equation}
    r_{\varepsilon, 2}(\mtx{B}) = \min \{1 \leq r \leq n: \mu_{r+1} \leq \varepsilon \}
    \label{equ:3-nystrom-SS-def-numerical-low-rank-spectral-norm}
\end{equation}

For Frobenius norm
\begin{equation}
    r_{\varepsilon, F}(\mtx{B}) = \min \{1 \leq r \leq n: \sqrt{\sum_{j=r+1}^n \mu_{j}^2} \leq \varepsilon \}
    \label{equ:3-nystrom-SS-def-numerical-low-rank-frobenius-norm}
\end{equation}

The eigenvalues of $g_{\sigma}(t\mtx{I} - \mtx{A})$ are
\begin{equation}
    \mu_i(t) = g_{\sigma}(t - \lambda_{(i)}) = \frac{1}{n \sqrt{2 \pi \sigma^2}} e^{-\frac{(t - \lambda_{(i)})^2}{2 \sigma^2}}
\end{equation}
Hence, 
\begin{equation}
    r_{\varepsilon, \cdot}(g_{\sigma}(t\mtx{I} - \mtx{A})) = \#\{1\leq i\leq n: |t - \mu_i(t)| \leq C_{\varepsilon, \cdot}(\sigma)\}
\end{equation}
with the distances
\begin{align}
    C_{\varepsilon, 2}(\sigma) = \sigma \sqrt{-2 \log(n \sqrt{2 \pi} \sigma \varepsilon)} \\
    C_{\varepsilon, F}(\sigma) = \sigma \sqrt{-2 \log(\sqrt{2 \pi} \sigma \varepsilon)}
\end{align}
\reffig{fig:3-nystrom-numerical-rank-constant}

\begin{figure}
    \centering
    \begin{tikzpicture}
        \fill[lightblue] (-2, -0.15) rectangle (1.5, 0.15);
        \draw[thick, ->] (-5, 0) to (5, 0);
        \fill[darkblue] (-4, 0) circle (0.075) node[above] {$\lambda_1$};
        \fill[darkblue] (-3, 0) circle (0.075) node[above] {$\lambda_2$};
        \fill[darkblue] (-2.4, 0) circle (0.075) node[above] {$\lambda_3$};
        \fill[darkblue] (-1, 0) circle (0.075) node[above] {$\lambda_4$};
        \fill[darkblue] (0.3, 0) circle (0.075) node[above] {$\lambda_5$};
        \fill[darkblue] (1, 0) circle (0.075) node[above] {$\lambda_6$};
        \fill[darkblue] (2.8, 0) circle (0.075) node[above] {$\lambda_7$};
        \fill[darkblue] (3.6, 0) circle (0.075) node[above] {$\lambda_8$};
        \fill[darkblue] (4, 0) circle (0.075) node[above] {$\lambda_9$};
        \draw[darkblue, ultra thick] (-0.155, 0.15) to (-0.155, -0.15) node[below] {$t$};
        \draw[darkblue, thick] (-2, 0.15) to (-2, -0.15) node[below] {$t - C_{\varepsilon, \cdot}(\sigma)$};
        \draw[darkblue, thick] (1.5, 0.15) to (1.5, -0.15) node[below] {$t + C_{\varepsilon, \cdot}(\sigma)$};
    \end{tikzpicture}
    \caption{The numerical rank}
    \label{fig:3-nystrom-numerical-rank-constant}
\end{figure}

If we assume the eigenvalues of the matrix $\mtx{A}$ in \refequ{equ:1-introduction-spectral-density-as-trace}
to be evenly distributed in $[a, b]$, i.e. in any subinterval of fixed length in
$[a, b]$ we can expect to find roughly the same number of eigenvalues (see \reffig{fig:3-nystrom-evenly-distributed-spectrum}), then
we can estimate the numerical rank of $g_{\sigma}(t\mtx{I} - \mtx{A})$.
\begin{equation}
    r_{\varepsilon, \cdot}(g_{\sigma}(t\mtx{I} - \mtx{A})) = \frac{2 n}{b - a} C_{\varepsilon, \cdot}(\sigma)
\end{equation}

\begin{figure}
    \centering
    \begin{subfigure}[b]{0.45\columnwidth}
        \begin{tikzpicture}
            \draw[thick, ->] (-1, -1) to (5, -1)  node[above] {$t$};
            %\node[anchor=east] at (-1.5, -1) {unevenly distributed};
            \fill[darkblue] (-0.5, -1) circle (0.075);
            \fill[darkblue] (-0.1, -1) circle (0.075);
            \fill[darkblue] (0.9, -1) circle (0.075);
            \fill[darkblue] (2.15, -1) circle (0.075);
            \fill[darkblue] (2.3, -1) circle (0.075);
            \fill[darkblue] (2.5, -1) circle (0.075);
            \fill[darkblue] (2.8, -1) circle (0.075);
            \fill[darkblue] (3.6, -1) circle (0.075);
            \fill[darkblue] (4, -1) circle (0.075);
            \draw[<-] (2.5, -1.1) to (2.5, -1.4) node[below] {higher rank};
            \draw[<-] (0.2, -1.1) to (0.2, -1.4) node[below] {lower rank};
        \end{tikzpicture}
        \caption{Unevenly distributed spectrum}
    \end{subfigure}
    \begin{subfigure}[b]{0.45\columnwidth}
        \begin{tikzpicture}
            \draw[thick, ->] (-1, 0) to (5, 0)  node[above] {$t$};
            %\node[anchor=east] at (-1.5, 0) {evenly distributed};
            \fill[darkblue] (-0.6, 0) circle (0.075);
            \fill[darkblue] (0, 0) circle (0.075);
            \fill[darkblue] (0.55, 0) circle (0.075);
            \fill[darkblue] (1.2, 0) circle (0.075);
            \fill[darkblue] (1.9, 0) circle (0.075);
            \fill[darkblue] (2.45, 0) circle (0.075);
            \fill[darkblue] (3, 0) circle (0.075);
            \fill[darkblue] (3.6, 0) circle (0.075);
            \fill[darkblue] (4.2, 0) circle (0.075);
        \end{tikzpicture}
        \caption{Evenly distributed spectrum}
    \end{subfigure}      
    \caption{Examples of an evenly and unevenly distributed spectrum.}
    \label{fig:3-nystrom-evenly-distributed-spectrum}
\end{figure}


\begin{figure}[ht]
    \centering
    \begin{tikzpicture}
        \node at (0, 0) {\input{plots/singular_value_decay.pgf}};
        \node at (2.9, 2.4) {\input{plots/singular_value_decay_colormap.pgf}};
    \end{tikzpicture}
    \caption{Singular value decay. \todo{add spectrum to show why not lowrank}}
    \label{fig:3-nystrom-singular-value-decay}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{The Nystr\"om low-rank approximation}
\label{sec:3-nystrom-nystrom}

Explain sketching [Tropp/Webber 2023, Lin 2017]

Nystr√∂m approximation \cite{gittens2013nystrom}
Sketching matrix $\mtx{\Omega} \in \mathbb{R}^{n \times n_v}$ [cite]
\begin{equation}
    \widehat{\mtx{B}} = (\mtx{B} \mtx{\Omega}) (\mtx{\Omega}^{\top} \mtx{B} \mtx{\Omega})^{\dagger} (\mtx{B} \mtx{\Omega})^{\top}
    \label{equ:3-nystrom-SS-nystrom}
\end{equation}

Cyclic property of trace
\begin{equation}
    \Tr(\widehat{\mtx{B}})
        = \Tr\left((\mtx{B} \mtx{\Omega}) (\mtx{\Omega}^{\top} \mtx{B} \mtx{\Omega})^{\dagger} (\mtx{B} \mtx{\Omega})^{\top} \right)
        = \Tr\left((\mtx{\Omega}^{\top} \mtx{B} \mtx{\Omega})^{\dagger} (\mtx{\Omega}^{\top} \mtx{B}^2 \mtx{\Omega}) \right)
    \label{equ:3-nystrom-nystrom-trace}
\end{equation}

Consistency between the two matrices (maybe don't even mention spectrum sweeping)
\begin{equation}
    \widetilde{\phi}_{\sigma}^m(t)
        = \Tr\left((\mtx{\Omega}^{\top} g_{\sigma}^m(t\mtx{I} - \mtx{A}) \mtx{\Omega})^{\dagger} (\mtx{\Omega}^{\top} (g_{\sigma}^m(t\mtx{I} - \mtx{A}))^2 \mtx{\Omega})\right)
    \label{equ:3-nystrom-spectral-density}
\end{equation}

\cite{lin2017randomized} suggests interpolation using a quadrature rule.
Analogous to \refequ{equ:2-chebyshev-chebyshev-expansion}
\begin{equation}
    (g_{\sigma}^m(t\mtx{I} - \mtx{A}))^2 = \sum_{l=0}^{2m} \nu_l(t) T_l(A)
    \label{equ:3-nystrom-ESS-chebyshev-expansion}
\end{equation}

Discuss inconsistency issue. Need to do direct squaring to get consistent.

The \gls{DCT}-property of the Chebyshev interpolation shown in \refequ{equ:2-chebyshev-chebyshev-DCT}
gives rise to fast exact multiplication algorithms between polynomials
of the form \refequ{equ:2-chebyshev-chebyshev-expansion} \cite[Proposition~3.1]{baszenski1997cosine}.
In fact, raising such a Chebyshev expansion to an integer power can be achieved
efficiently via a \gls{DCT} and inverse \gls{DCT}.

Suppose we have computed the coefficients $\vct{\mu} \in \mathbb{R}^{m+1}$
of a Chebyshev expansion \refequ{equ:2-chebyshev-chebyshev-expansion}.
Then we may quickly compute the coefficients $\vct{\nu} \in \mathbb{R}^{km+1}$
of the same expansion raised to the power $k \geq 2$ by first zero-padding
$\widehat{\vct{\mu}} = [\vct{\mu}^{\top}, \vct{0}_{(k-1)m}^{\top}]^{\top} \in \mathbb{R}^{km+1}$
and subsequently compute
\begin{equation}
    \vct{\nu} = (km + 1)^{k - 1} \DCT^{-1}\left\{ \DCT\left\{\widehat{\vct{\mu}}^{k}\right\} \right\}
    \label{equ:3-nystrom-chebyshev-square-coefficients}
\end{equation}
where the exponentiation of a vector is understood elementwise.

Explanation of interpolation issue \cite{lin2017randomized}

This is exactly equivalent to \cite[Algorithm~5]{lin2017randomized}
\begin{figure}[ht]
    \centering
    \input{plots/interpolation_issue.pgf}
    \caption{Interpolation issue.}
    \label{fig:3-nystrom-interpolation-issue}
\end{figure}

$\Xi(t)$ permutation of eigenvalues of $g_{\sigma}(tI - A)$
Filtering $[0, 1 / (n \sqrt{2 \pi \sigma^2})]$ \cite{lin2017randomized}
Adding some tolerance to avoid filtering

Not solving the generalized eigenvalue problem if spectral density zero (rank matrix zero).

\begin{algo}{Nystr\"om-Chebyshev method}{nystrom-chebyshev}
    symmetric matrix $\mtx{A} \in \mathbb{R}^{n \times n}$, number of random vectors $n_v$,
    evaluation points $\{t_i\}_{i=1}^{n_t}$
    \begin{algorithmic}[1]
        \State Compute $\{\mu_l(t_i)\}_{l=0}^m$ for all $t_i$ using \refequ{equ:2-chebyshev-chebyshev-DCT}
        \State Compute $\{\nu_l(t_i)\}_{l=0}^{2m}$ for all $t_i$ using \refequ{equ:3-nystrom-chebyshev-square-coefficients}
        \State Generate sketching matrix $\mtx{\Omega} \in \mathbb{R}^{n \times n_v}$ % TODO add \Omega to glossary (and Psi is only random matrix)
        \State Initialize $[\mtx{V}_1, \mtx{V}_2, \mtx{V}_3] \gets [\mtx{0}_{n \times n_v}, \mtx{\Omega}, \mtx{0}_{n \times n_v}]$
        \State Initialize $[\mtx{K}_1(t_i), \mtx{K}_2(t_i)] \gets [\mtx{0}_{n_v \times n_v}, \mtx{0}_{n_v \times n_v}]$ for all $t_i$
        \State Set ${\phi}_{\sigma}^m(t_i) \gets 0$ for $i=1,\dots,n_t$
        \For {$l = 0, \dots, m$}
          \State $\mtx{X} \gets \mtx{\Omega}^{\top} \mtx{V}_2$
          \For {$i = 1, \dots, n_t$}
            \If {$l \leq m$}
                \State $\mtx{K}_1(t_i) \gets \mtx{K}_1(t_i) + \mu_l(t_i) \mtx{X}$
            \EndIf
            \State $\mtx{K}_2(t_i) \gets \mtx{K}_2(t_i) + \nu_l(t_i) \mtx{X}$
          \EndFor
          \State $\mtx{V}_3 \gets (2 - \delta_{l0}) \mtx{A} \mtx{V}_2 - \mtx{V}_1$ \Comment{Chebyshev recurrence \refequ{equ:2-chebyshev-chebyshev-recursion}}
          \State $\mtx{V}_1 \gets \mtx{V}_2, \mtx{V}_2 \gets \mtx{V}_3$
        \EndFor
        \For {$i = 1, \dots, n_t$}
          \State Compute $\widetilde{\phi}_{\sigma}^m(t_i) \gets \Tr\left( \mtx{K}_2(t_i)^{\dagger}\mtx{K}_1(t_i) \right)$
        \EndFor
    \end{algorithmic}
\end{algo}

Computational complexity: $\mathcal{O}(m \log(m) n_t + m n_v^2 n + m n_t n_v^2 +  m c(n) n_v + n_t n_v^3)$
Additional storage complexity: $\mathcal{O}(n n_v + n_v^2 n_t + m n_t)$

Error guarantee from \cite[Theorem~9]{kressner2023randomized}, combine with Chebyshev.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Implementation details}
\label{sec:3-nystrom-implementation-details}

Computation of pseudo-inverse

- Generalized eigenvalue problem

- Eigenvalue filtering with tolerance adjustment
\begin{equation}
    (\mtx{\Omega}^{\top} (g_{\sigma}^m(t\mtx{I} - \mtx{A}))^2 \mtx{\Omega}) \mtx{C}(t) = (\mtx{\Omega}^{\top} g_{\sigma}^m(t\mtx{I} - \mtx{A}) \mtx{\Omega}) \mtx{C}(t) \mtx{\Xi}(t)
    \label{equ:3-nystrom-generalized-eigenproblem}
\end{equation}

Maybe proof of this GEP?

Short-circuit: Not a good idea to compute pseudoinverse if
both $\mtx{K}_1$ and $\mtx{K}_2$ are zero (noise divided by noise)
\begin{equation}
    \phi_{\sigma}^m(t_i) \approx \frac{1}{n_v} \Tr(\mtx{K}_1(t_i))
    \label{equ:3-nystrom-shortcircuit-hutchinson}
\end{equation}
If smaller than a threshold $\delta = 10^{-5}$

\begin{figure}[ht]
    \centering
    \input{plots/short_circuit_mechanism.pgf}
    \caption{Short-circuit mechanism.}
    \label{fig:3-nystrom-short-circuit-mechanism}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Other low-rank approximations}
\label{sec:3-nystrom-other-low-rank}

Many other methods fit into this scheme. (RSVD, Nystrom-SI)
Generalization of \refequ{equ:3-nystrom-nystrom-trace}
\begin{equation}
    \Tr(\widehat{\mtx{B}}^{(k)})
        = \Tr\left((\mtx{\Omega}^{\top} \mtx{B}^k \mtx{\Omega})^{\dagger} (\mtx{\Omega}^{\top} \mtx{B}^{k+1} \mtx{\Omega}) \right)
    \label{equ:3-nystrom-trace-generalization}
\end{equation}

$\widehat{\mtx{B}}^{(1)}$ Nystr\"om approximation discussed in \refsec{sec:3-nystrom-nystrom}.

Randomized low-rank approximation \cite{halko2011finding, tropp2023randomized}
\begin{equation}
    \widehat{\mtx{B}}^{(2)} = (\mtx{B} \mtx{\Omega}) ((\mtx{B} \mtx{\Omega})^{\top} (\mtx{B} \mtx{\Omega}))^{\dagger} (\mtx{B} \mtx{\Omega})^{\top} \mtx{B}
    \label{equ:3-nystrom-RSVD}
\end{equation}

Nystr\"om with subspace iteration \cite{tropp2023randomized}
\begin{equation}
    \widehat{\mtx{B}}^{(3)} = (\mtx{B}^2 \mtx{\Omega}) (\mtx{\Omega}^{\top} \mtx{B}^3 \mtx{\Omega})^{\dagger} (\mtx{B}^2 \mtx{\Omega})^{\top}
    \label{equ:3-nystrom-nystrom-SI}
\end{equation}
